hostname sb031.cluster
ipconfig 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: enp4s0f0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 9000 qdisc mq state UP group default qlen 1000 link/ether a0:8c:f8:34:c9:e4 brd ff:ff:ff:ff:ff:ff inet 10.3.81.111/22 brd 10.3.83.255 scope global enp4s0f0 valid_lft forever preferred_lft forever inet6 fe80::a28c:f8ff:fe34:c9e4/64 scope link valid_lft forever preferred_lft forever 3: enp4s0f1: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether a0:8c:f8:34:c9:e5 brd ff:ff:ff:ff:ff:ff 4: enp4s0f2: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether a0:8c:f8:34:c9:e6 brd ff:ff:ff:ff:ff:ff 5: enp4s0f3: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether a0:8c:f8:34:c9:e7 brd ff:ff:ff:ff:ff:ff 6: ib0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 4092 qdisc pfifo_fast state UP group default qlen 256 link/infiniband 80:00:00:29:fe:80:00:00:00:00:00:00:38:bc:01:03:00:4c:f7:10 brd 00:ff:ff:ff:ff:12:40:1b:ff:ff:00:00:00:00:00:00:ff:ff:ff:ff inet 10.3.89.111/22 brd 10.3.91.255 scope global ib0 valid_lft forever preferred_lft forever inet 10.3.93.111/22 brd 10.3.95.255 scope global ib0:1 valid_lft forever preferred_lft forever inet6 fe80::3abc:103:4c:f710/64 scope link valid_lft forever preferred_lft forever 7: ib1: <BROADCAST,MULTICAST> mtu 4092 qdisc noop state DOWN group default qlen 256 link/infiniband 80:00:00:29:fe:80:00:00:00:00:00:00:38:bc:01:03:00:4c:f7:11 brd 00:ff:ff:ff:ff:12:40:1b:ff:ff:00:00:00:00:00:00:ff:ff:ff:ff
2024-01-28 18:30:01,747 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.3.89.111:42823'
2024-01-28 18:30:12,996 - distributed.worker - INFO -       Start worker at:    tcp://10.3.89.111:45730
2024-01-28 18:30:12,997 - distributed.worker - INFO -          Listening to:    tcp://10.3.89.111:45730
2024-01-28 18:30:12,997 - distributed.worker - INFO -           Worker name:           SLURMCluster-483
2024-01-28 18:30:12,997 - distributed.worker - INFO -          dashboard at:          10.3.89.111:45480
2024-01-28 18:30:12,997 - distributed.worker - INFO - Waiting to connect to:     tcp://10.3.88.11:44532
2024-01-28 18:30:12,997 - distributed.worker - INFO - -------------------------------------------------
2024-01-28 18:30:12,997 - distributed.worker - INFO -               Threads:                          2
2024-01-28 18:30:12,998 - distributed.worker - INFO -                Memory:                  20.49 GiB
2024-01-28 18:30:12,998 - distributed.worker - INFO -       Local Directory: /scratch/dask-worker-space/worker-2p3uyvxz
2024-01-28 18:30:12,998 - distributed.worker - INFO - -------------------------------------------------
2024-01-28 18:30:13,068 - distributed.worker - INFO -         Registered to:     tcp://10.3.88.11:44532
2024-01-28 18:30:13,069 - distributed.worker - INFO - -------------------------------------------------
2024-01-28 18:30:13,069 - distributed.core - INFO - Starting established connection to tcp://10.3.88.11:44532
2024-01-28 18:46:07,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 18:46:25,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 18:57:01,069 - distributed.core - INFO - Event loop was unresponsive in Worker for 29.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 18:57:01,069 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 29.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/__init__.py:55: UserWarning: Dependency not satisfied, torchani.ase will not be available
  warnings.warn("Dependency not satisfied, torchani.ase will not be available")
2024-01-28 18:57:48,104 [WARNING] [__init__.py:5] root: Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.
2024-01-28 18:57:55,396 - distributed.nanny - INFO - Worker process 44458 was killed by signal 11
2024-01-28 18:57:55,404 - distributed.nanny - WARNING - Restarting worker
2024-01-28 18:58:06,089 - distributed.worker - INFO -       Start worker at:    tcp://10.3.89.111:46351
2024-01-28 18:58:06,090 - distributed.worker - INFO -          Listening to:    tcp://10.3.89.111:46351
2024-01-28 18:58:06,090 - distributed.worker - INFO -           Worker name:           SLURMCluster-483
2024-01-28 18:58:06,090 - distributed.worker - INFO -          dashboard at:          10.3.89.111:44609
2024-01-28 18:58:06,091 - distributed.worker - INFO - Waiting to connect to:     tcp://10.3.88.11:44532
2024-01-28 18:58:06,091 - distributed.worker - INFO - -------------------------------------------------
2024-01-28 18:58:06,091 - distributed.worker - INFO -               Threads:                          2
2024-01-28 18:58:06,091 - distributed.worker - INFO -                Memory:                  20.49 GiB
2024-01-28 18:58:06,091 - distributed.worker - INFO -       Local Directory: /scratch/dask-worker-space/worker-vl5rihii
2024-01-28 18:58:06,091 - distributed.worker - INFO - -------------------------------------------------
2024-01-28 18:58:06,142 - distributed.worker - INFO -         Registered to:     tcp://10.3.88.11:44532
2024-01-28 18:58:06,142 - distributed.worker - INFO - -------------------------------------------------
2024-01-28 18:58:06,143 - distributed.core - INFO - Starting established connection to tcp://10.3.88.11:44532
2024-01-28 18:58:24,677 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 18:58:24,677 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 18.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
2024-01-28 18:58:35,696 [WARNING] [rdkit_wrapper.py:3213] openff.toolkit.utils.rdkit_wrapper: Warning (not error because allow_undefined_stereo=True): RDMol has unspecified stereochemistry. Undefined chiral centers are:
 - Atom C (index 8)

2024-01-28 18:58:38,901 [WARNING] [rdkit_wrapper.py:3213] openff.toolkit.utils.rdkit_wrapper: Warning (not error because allow_undefined_stereo=True): RDMol has unspecified stereochemistry. Undefined chiral centers are:
 - Atom C (index 8)

/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/__init__.py:55: UserWarning: Dependency not satisfied, torchani.ase will not be available
  warnings.warn("Dependency not satisfied, torchani.ase will not be available")
2024-01-28 18:59:24,167 [WARNING] [__init__.py:5] root: Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.
TIME changed dir: 0.0s
TIME changed dir: 0.0s
Generated 19 conformers. 
Removed 9 conformers. 
Generated 36 conformers. 
Removed 32 conformers. 
using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
failed to equip `nnpops` with error: No module named 'NNPOps'
Optimising conformer:   0%|                              | 0/10 [00:00<?, ?it/s][W BinaryOps.cpp:601] Warning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (function operator())
failed to equip `nnpops` with error: No module named 'NNPOps'

Optimising conformer:   0%|                               | 0/4 [00:00<?, ?it/s][A
Optimising conformer:  25%|█████▊                 | 1/4 [00:05<00:17,  5.92s/it][AOptimising conformer:  10%|██▏                   | 1/10 [00:10<01:34, 10.51s/it]Optimising conformer:  20%|████▍                 | 2/10 [00:12<00:46,  5.75s/it]
Optimising conformer:  50%|███████████▌           | 2/4 [00:10<00:10,  5.04s/it][AOptimising conformer:  30%|██████▌               | 3/10 [00:16<00:31,  4.54s/it]Optimising conformer:  40%|████████▊             | 4/10 [00:17<00:21,  3.52s/it]
Optimising conformer:  75%|█████████████████▎     | 3/4 [00:16<00:05,  5.54s/it][AOptimising conformer:  50%|███████████           | 5/10 [00:20<00:14,  2.98s/it]Optimising conformer:  60%|█████████████▏        | 6/10 [00:24<00:13,  3.43s/it]Optimising conformer:  70%|███████████████▍      | 7/10 [00:28<00:11,  3.80s/it]Optimising conformer:  80%|█████████████████▌    | 8/10 [00:30<00:06,  3.23s/it]Optimising conformer:  90%|███████████████████▊  | 9/10 [00:32<00:02,  2.77s/it]Optimising conformer: 100%|█████████████████████| 10/10 [00:35<00:00,  2.71s/it]Optimising conformer: 100%|█████████████████████| 10/10 [00:35<00:00,  3.52s/it]
/mnt/storage/nobackup/nmb1063/code/gal/sars-cov-2-main-protease-al-study-plip/rsearcher.py:89: UserWarning: The ligand was an array (SDF?). Using the first frame. 
  warnings.warn("The ligand was an array (SDF?). Using the first frame. ")

Optimising conformer: 100%|███████████████████████| 4/4 [00:37<00:00, 11.48s/it][AOptimising conformer: 100%|███████████████████████| 4/4 [00:37<00:00,  9.27s/it]
2024-01-28 19:17:38,029 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 19:17:38,029 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 6.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
2024-01-28 19:28:18,539 [WARNING] [rdkit_wrapper.py:3213] openff.toolkit.utils.rdkit_wrapper: Warning (not error because allow_undefined_stereo=True): RDMol has unspecified stereochemistry. Undefined chiral centers are:
 - Atom C (index 1)

/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
2024-01-28 19:28:20,383 [WARNING] [rdkit_wrapper.py:3213] openff.toolkit.utils.rdkit_wrapper: Warning (not error because allow_undefined_stereo=True): RDMol has unspecified stereochemistry. Undefined chiral centers are:
 - Atom C (index 1)

TIME Completed the molecule generation in 109.2s.
TIME Completed the molecule generation in 113.3s.
TIME changed dir: 0.0s
TIME changed dir: 0.0s
Generated 30 conformers. 
Removed 13 conformers. 
Generated 46 conformers. 
Removed 24 conformers. 
using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
failed to equip `nnpops` with error: No module named 'NNPOps'
Optimising conformer:   0%|                              | 0/17 [00:00<?, ?it/s]Optimising conformer:   6%|█▎                    | 1/17 [00:03<00:50,  3.13s/it]Optimising conformer:  12%|██▌                   | 2/17 [00:05<00:39,  2.62s/it]Optimising conformer:  18%|███▉                  | 3/17 [00:08<00:38,  2.75s/it]Optimising conformer:  24%|█████▏                | 4/17 [00:11<00:37,  2.88s/it]Optimising conformer:  29%|██████▍               | 5/17 [00:13<00:30,  2.56s/it]Optimising conformer:  35%|███████▊              | 6/17 [00:17<00:34,  3.14s/it]Optimising conformer:  41%|█████████             | 7/17 [00:19<00:28,  2.88s/it]Optimising conformer:  47%|██████████▎           | 8/17 [00:22<00:26,  2.91s/it]Optimising conformer:  53%|███████████▋          | 9/17 [00:25<00:21,  2.74s/it]Optimising conformer:  59%|████████████▎        | 10/17 [00:28<00:19,  2.79s/it]Optimising conformer:  65%|█████████████▌       | 11/17 [00:30<00:16,  2.77s/it]Optimising conformer:  71%|██████████████▊      | 12/17 [00:34<00:14,  2.98s/it]Optimising conformer:  76%|████████████████     | 13/17 [00:37<00:12,  3.01s/it]Optimising conformer:  82%|█████████████████▎   | 14/17 [00:40<00:08,  2.97s/it]Optimising conformer:  88%|██████████████████▌  | 15/17 [00:42<00:05,  2.84s/it]Optimising conformer:  94%|███████████████████▊ | 16/17 [00:45<00:02,  2.86s/it]Optimising conformer: 100%|█████████████████████| 17/17 [00:48<00:00,  2.75s/it]Optimising conformer: 100%|█████████████████████| 17/17 [00:48<00:00,  2.84s/it]
/mnt/storage/nobackup/nmb1063/code/gal/sars-cov-2-main-protease-al-study-plip/rsearcher.py:89: UserWarning: The ligand was an array (SDF?). Using the first frame. 
  warnings.warn("The ligand was an array (SDF?). Using the first frame. ")
2024-01-28 19:29:44,061 [WARNING] [rdkit_wrapper.py:3213] openff.toolkit.utils.rdkit_wrapper: Warning (not error because allow_undefined_stereo=True): RDMol has unspecified stereochemistry. Undefined chiral centers are:
 - Atom C (index 9)

/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
2024-01-28 19:29:46,065 [WARNING] [rdkit_wrapper.py:3213] openff.toolkit.utils.rdkit_wrapper: Warning (not error because allow_undefined_stereo=True): RDMol has unspecified stereochemistry. Undefined chiral centers are:
 - Atom C (index 9)

TIME Completed the molecule generation in 86.6s.
TIME changed dir: 0.0s
Generated 50 conformers. 
Removed 35 conformers. 
using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
failed to equip `nnpops` with error: No module named 'NNPOps'
Optimising conformer:   0%|                              | 0/22 [00:00<?, ?it/s]Optimising conformer:   5%|█                     | 1/22 [00:07<02:47,  7.98s/it]Optimising conformer:   9%|██                    | 2/22 [00:11<01:47,  5.39s/it]Optimising conformer:  14%|███                   | 3/22 [00:13<01:13,  3.87s/it]Optimising conformer:  18%|████                  | 4/22 [00:16<01:01,  3.39s/it]Optimising conformer:  23%|█████                 | 5/22 [00:19<00:57,  3.38s/it]Optimising conformer:  27%|██████                | 6/22 [00:22<00:53,  3.35s/it]Optimising conformer:  32%|███████               | 7/22 [00:28<01:00,  4.06s/it]Optimising conformer:  36%|████████              | 8/22 [00:32<00:58,  4.19s/it]using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
failed to equip `nnpops` with error: No module named 'NNPOps'

Optimising conformer:   0%|                              | 0/15 [00:00<?, ?it/s][A
Optimising conformer:   7%|█▍                    | 1/15 [00:05<01:18,  5.60s/it][AOptimising conformer:  41%|█████████             | 9/22 [00:39<01:05,  5.00s/it]Optimising conformer:  45%|█████████▌           | 10/22 [00:41<00:49,  4.12s/it]Optimising conformer:  50%|██████████▌          | 11/22 [00:46<00:46,  4.25s/it]
Optimising conformer:  13%|██▉                   | 2/15 [00:14<01:35,  7.36s/it][AOptimising conformer:  55%|███████████▍         | 12/22 [00:50<00:42,  4.26s/it]
Optimising conformer:  20%|████▍                 | 3/15 [00:19<01:17,  6.45s/it][AOptimising conformer:  59%|████████████▍        | 13/22 [00:53<00:34,  3.87s/it]
Optimising conformer:  27%|█████▊                | 4/15 [00:25<01:10,  6.42s/it][AOptimising conformer:  64%|█████████████▎       | 14/22 [00:59<00:36,  4.58s/it]Optimising conformer:  68%|██████████████▎      | 15/22 [01:02<00:27,  3.99s/it]Optimising conformer:  73%|███████████████▎     | 16/22 [01:04<00:20,  3.39s/it]
Optimising conformer:  33%|███████▎              | 5/15 [00:31<01:01,  6.18s/it][AOptimising conformer:  77%|████████████████▏    | 17/22 [01:06<00:14,  2.97s/it]Optimising conformer:  82%|█████████████████▏   | 18/22 [01:10<00:12,  3.20s/it]
Optimising conformer:  40%|████████▊             | 6/15 [00:37<00:53,  5.99s/it][AOptimising conformer:  86%|██████████████████▏  | 19/22 [01:12<00:09,  3.02s/it]
Optimising conformer:  47%|██████████▎           | 7/15 [00:40<00:41,  5.15s/it][AOptimising conformer:  91%|███████████████████  | 20/22 [01:15<00:05,  2.99s/it]Optimising conformer:  95%|████████████████████ | 21/22 [01:20<00:03,  3.53s/it]Optimising conformer: 100%|█████████████████████| 22/22 [01:23<00:00,  3.40s/it]Optimising conformer: 100%|█████████████████████| 22/22 [01:23<00:00,  3.80s/it]
/mnt/storage/nobackup/nmb1063/code/gal/sars-cov-2-main-protease-al-study-plip/rsearcher.py:89: UserWarning: The ligand was an array (SDF?). Using the first frame. 
  warnings.warn("The ligand was an array (SDF?). Using the first frame. ")

Optimising conformer:  53%|███████████▋          | 8/15 [00:52<00:50,  7.24s/it][A
Optimising conformer:  60%|█████████████▏        | 9/15 [00:55<00:36,  6.08s/it][A
Optimising conformer:  67%|██████████████       | 10/15 [01:00<00:27,  5.53s/it][A
Optimising conformer:  73%|███████████████▍     | 11/15 [01:03<00:19,  4.78s/it][A
Optimising conformer:  80%|████████████████▊    | 12/15 [01:07<00:13,  4.64s/it][A
Optimising conformer:  87%|██████████████████▏  | 13/15 [01:10<00:08,  4.06s/it][A
Optimising conformer:  93%|███████████████████▌ | 14/15 [01:13<00:03,  3.85s/it][A
Optimising conformer: 100%|█████████████████████| 15/15 [01:33<00:00,  8.50s/it][AOptimising conformer: 100%|█████████████████████| 15/15 [01:33<00:00,  6.20s/it]
2024-01-28 19:47:23,837 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 19:47:23,837 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 19:47:26,880 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 19:47:26,880 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 19:47:48,569 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 19:47:48,569 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
TIME Completed the molecule generation in 198.5s.
TIME Completed the molecule generation in 154.5s.
TIME changed dir: 0.0s
TIME changed dir: 0.0s
Generated 2 conformers. 
Removed 0 conformers. 
Generated 9 conformers. 
Removed 5 conformers. 
using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
failed to equip `nnpops` with error: No module named 'NNPOps'
using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
Optimising conformer:   0%|                               | 0/2 [00:00<?, ?it/s]Optimising conformer:  50%|███████████▌           | 1/2 [00:02<00:02,  2.31s/it]Optimising conformer: 100%|███████████████████████| 2/2 [00:05<00:00,  2.76s/it]Optimising conformer: 100%|███████████████████████| 2/2 [00:05<00:00,  2.70s/it]
/mnt/storage/nobackup/nmb1063/code/gal/sars-cov-2-main-protease-al-study-plip/rsearcher.py:89: UserWarning: The ligand was an array (SDF?). Using the first frame. 
  warnings.warn("The ligand was an array (SDF?). Using the first frame. ")
failed to equip `nnpops` with error: No module named 'NNPOps'
TIME Completed the molecule generation in 54.4s.
TIME changed dir: 0.0s
Optimising conformer:   0%|                               | 0/4 [00:00<?, ?it/s]/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
Optimising conformer:  25%|█████▊                 | 1/4 [00:05<00:15,  5.06s/it]Optimising conformer:  50%|███████████▌           | 2/4 [00:08<00:07,  3.96s/it]Optimising conformer:  75%|█████████████████▎     | 3/4 [00:10<00:03,  3.19s/it]Optimising conformer: 100%|███████████████████████| 4/4 [00:12<00:00,  2.80s/it]Optimising conformer: 100%|███████████████████████| 4/4 [00:12<00:00,  3.18s/it]
/mnt/storage/nobackup/nmb1063/code/gal/sars-cov-2-main-protease-al-study-plip/rsearcher.py:89: UserWarning: The ligand was an array (SDF?). Using the first frame. 
  warnings.warn("The ligand was an array (SDF?). Using the first frame. ")
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
Generated 12 conformers. 
Removed 8 conformers. 
TIME Completed the molecule generation in 71.4s.
TIME changed dir: 0.0s
Generated 22 conformers. 
Removed 16 conformers. 
using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
failed to equip `nnpops` with error: No module named 'NNPOps'
Optimising conformer:   0%|                               | 0/4 [00:00<?, ?it/s]Optimising conformer:  25%|█████▊                 | 1/4 [00:04<00:13,  4.37s/it]Optimising conformer:  50%|███████████▌           | 2/4 [00:07<00:07,  3.70s/it]Optimising conformer:  75%|█████████████████▎     | 3/4 [00:10<00:03,  3.30s/it]Optimising conformer: 100%|███████████████████████| 4/4 [00:12<00:00,  2.71s/it]Optimising conformer: 100%|███████████████████████| 4/4 [00:12<00:00,  3.06s/it]
/mnt/storage/nobackup/nmb1063/code/gal/sars-cov-2-main-protease-al-study-plip/rsearcher.py:89: UserWarning: The ligand was an array (SDF?). Using the first frame. 
  warnings.warn("The ligand was an array (SDF?). Using the first frame. ")
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
TIME Completed the molecule generation in 71.2s.
TIME changed dir: 0.0s
Generated 8 conformers. 
Removed 2 conformers. 
using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
failed to equip `nnpops` with error: No module named 'NNPOps'
Optimising conformer:   0%|                               | 0/6 [00:00<?, ?it/s]Optimising conformer:  17%|███▊                   | 1/6 [00:03<00:15,  3.18s/it]Optimising conformer:  33%|███████▋               | 2/6 [00:04<00:09,  2.37s/it]Optimising conformer:  50%|███████████▌           | 3/6 [00:07<00:07,  2.61s/it]Optimising conformer:  67%|███████████████▎       | 4/6 [00:10<00:05,  2.77s/it]Optimising conformer:  83%|███████████████████▏   | 5/6 [00:14<00:02,  2.92s/it]using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
failed to equip `nnpops` with error: No module named 'NNPOps'

Optimising conformer:   0%|                               | 0/6 [00:00<?, ?it/s][AOptimising conformer: 100%|███████████████████████| 6/6 [00:16<00:00,  2.76s/it]Optimising conformer: 100%|███████████████████████| 6/6 [00:16<00:00,  2.75s/it]
/mnt/storage/nobackup/nmb1063/code/gal/sars-cov-2-main-protease-al-study-plip/rsearcher.py:89: UserWarning: The ligand was an array (SDF?). Using the first frame. 
  warnings.warn("The ligand was an array (SDF?). Using the first frame. ")

Optimising conformer:  17%|███▊                   | 1/6 [00:02<00:13,  2.74s/it][A
Optimising conformer:  33%|███████▋               | 2/6 [00:04<00:09,  2.41s/it][A
Optimising conformer:  50%|███████████▌           | 3/6 [00:06<00:06,  2.21s/it][A
Optimising conformer:  67%|███████████████▎       | 4/6 [00:07<00:03,  1.67s/it][A
Optimising conformer:  83%|███████████████████▏   | 5/6 [00:09<00:01,  1.82s/it][A
Optimising conformer: 100%|███████████████████████| 6/6 [00:12<00:00,  1.96s/it][AOptimising conformer: 100%|███████████████████████| 6/6 [00:12<00:00,  2.01s/it]
2024-01-28 20:18:41,050 - distributed.core - INFO - Event loop was unresponsive in Nanny for 64.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 20:18:41,105 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 20:18:41,105 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 64.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 20:19:36,374 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 20:19:36,374 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 7.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 20:19:58,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 20:19:58,057 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 3.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 20:20:01,690 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 20:20:01,690 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 20:27:29,877 - distributed.core - INFO - Event loop was unresponsive in Nanny for 62.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-28 20:27:29,899 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/tornado/iostream.py", line 1124, in write_to_fd
    return self.socket.send(data)  # type: ignore
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/worker.py", line 1237, in heartbeat
    response = await retry_operation(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry_operation
    return await retry(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/utils_comm.py", line 413, in retry
    return await coro()
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 1227, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 986, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/comm/tcp.py", line 241, in read
    convert_stream_closed_error(self, e)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.3.89.111:57814 remote=tcp://10.3.88.11:44532>: TimeoutError: [Errno 110] Connection timed out
2024-01-28 20:27:29,899 [ERROR] [worker.py:1274] distributed.worker: Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/tornado/iostream.py", line 1124, in write_to_fd
    return self.socket.send(data)  # type: ignore
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/worker.py", line 1237, in heartbeat
    response = await retry_operation(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry_operation
    return await retry(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/utils_comm.py", line 413, in retry
    return await coro()
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 1227, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 986, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/comm/tcp.py", line 241, in read
    convert_stream_closed_error(self, e)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.3.89.111:57814 remote=tcp://10.3.88.11:44532>: TimeoutError: [Errno 110] Connection timed out
2024-01-28 20:27:29,910 - distributed.core - INFO - Connection to tcp://10.3.88.11:44532 has been closed.
2024-01-28 20:27:29,910 [INFO] [core.py:877] distributed.core: Connection to tcp://10.3.88.11:44532 has been closed.
2024-01-28 20:27:29,913 - distributed.worker - INFO - Stopping worker at tcp://10.3.89.111:46351. Reason: worker-handle-scheduler-connection-broken
2024-01-28 20:27:29,913 [INFO] [worker.py:1535] distributed.worker: Stopping worker at tcp://10.3.89.111:46351. Reason: worker-handle-scheduler-connection-broken
2024-01-28 20:27:29,924 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.3.89.111:42823'. Reason: worker-handle-scheduler-connection-broken
2024-01-28 20:27:29,936 - distributed.nanny - INFO - Worker closed
2024-01-28 20:27:29,936 [INFO] [nanny.py:945] distributed.nanny: Worker closed
2024-01-28 20:27:31,939 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-01-28 20:27:31,939 [ERROR] [nanny.py:901] distributed.nanny: Worker process died unexpectedly
TIME Completed the molecule generation in 99.6s.
TIME Completed the molecule generation in 57.3s.
2024-01-28 20:27:51,012 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.3.89.111:42823'. Reason: nanny-close-gracefully
2024-01-28 20:27:51,030 - distributed.dask_worker - INFO - End worker
