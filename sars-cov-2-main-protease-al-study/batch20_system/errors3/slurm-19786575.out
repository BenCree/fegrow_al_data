hostname sb045.cluster
ipconfig 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: enp4s0f0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 9000 qdisc mq state UP group default qlen 1000 link/ether a0:8c:f8:74:c8:c0 brd ff:ff:ff:ff:ff:ff inet 10.3.81.125/22 brd 10.3.83.255 scope global enp4s0f0 valid_lft forever preferred_lft forever inet6 fe80::a28c:f8ff:fe74:c8c0/64 scope link valid_lft forever preferred_lft forever 3: enp4s0f1: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether a0:8c:f8:74:c8:c1 brd ff:ff:ff:ff:ff:ff 4: enp4s0f2: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether a0:8c:f8:74:c8:c2 brd ff:ff:ff:ff:ff:ff 5: enp4s0f3: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether a0:8c:f8:74:c8:c3 brd ff:ff:ff:ff:ff:ff 6: ib0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 4092 qdisc pfifo_fast state UP group default qlen 256 link/infiniband 80:00:00:29:fe:80:00:00:00:00:00:00:38:bc:01:03:00:4c:f2:e0 brd 00:ff:ff:ff:ff:12:40:1b:ff:ff:00:00:00:00:00:00:ff:ff:ff:ff inet 10.3.89.125/22 brd 10.3.91.255 scope global ib0 valid_lft forever preferred_lft forever inet 10.3.93.125/22 brd 10.3.95.255 scope global ib0:1 valid_lft forever preferred_lft forever inet6 fe80::3abc:103:4c:f2e0/64 scope link valid_lft forever preferred_lft forever 7: ib1: <BROADCAST,MULTICAST> mtu 4092 qdisc noop state DOWN group default qlen 256 link/infiniband 80:00:00:29:fe:80:00:00:00:00:00:00:38:bc:01:03:00:4c:f2:e1 brd 00:ff:ff:ff:ff:12:40:1b:ff:ff:00:00:00:00:00:00:ff:ff:ff:ff
2024-01-19 08:00:40,432 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.3.89.125:33632'
2024-01-19 08:00:40,621 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.3.89.125:38841'
2024-01-19 08:01:01,853 - distributed.worker - INFO -       Start worker at:    tcp://10.3.89.125:36581
2024-01-19 08:01:01,853 - distributed.worker - INFO -       Start worker at:    tcp://10.3.89.125:36770
2024-01-19 08:01:01,854 - distributed.worker - INFO -          Listening to:    tcp://10.3.89.125:36581
2024-01-19 08:01:01,854 - distributed.worker - INFO -          Listening to:    tcp://10.3.89.125:36770
2024-01-19 08:01:01,854 - distributed.worker - INFO -           Worker name:         SLURMCluster-491-0
2024-01-19 08:01:01,854 - distributed.worker - INFO -           Worker name:         SLURMCluster-491-1
2024-01-19 08:01:01,854 - distributed.worker - INFO -          dashboard at:          10.3.89.125:33751
2024-01-19 08:01:01,854 - distributed.worker - INFO -          dashboard at:          10.3.89.125:35259
2024-01-19 08:01:01,854 - distributed.worker - INFO - Waiting to connect to:     tcp://10.3.88.12:42763
2024-01-19 08:01:01,854 - distributed.worker - INFO - Waiting to connect to:     tcp://10.3.88.12:42763
2024-01-19 08:01:01,854 - distributed.worker - INFO - -------------------------------------------------
2024-01-19 08:01:01,854 - distributed.worker - INFO - -------------------------------------------------
2024-01-19 08:01:01,854 - distributed.worker - INFO -               Threads:                          2
2024-01-19 08:01:01,854 - distributed.worker - INFO -               Threads:                          2
2024-01-19 08:01:01,854 - distributed.worker - INFO -                Memory:                  10.24 GiB
2024-01-19 08:01:01,854 - distributed.worker - INFO -                Memory:                  10.24 GiB
2024-01-19 08:01:01,854 - distributed.worker - INFO -       Local Directory: /scratch/dask-worker-space/worker-kjbuezln
2024-01-19 08:01:01,854 - distributed.worker - INFO -       Local Directory: /scratch/dask-worker-space/worker-r77l7qwy
2024-01-19 08:01:01,854 - distributed.worker - INFO - -------------------------------------------------
2024-01-19 08:01:01,854 - distributed.worker - INFO - -------------------------------------------------
2024-01-19 08:01:01,945 - distributed.worker - INFO -         Registered to:     tcp://10.3.88.12:42763
2024-01-19 08:01:01,946 - distributed.worker - INFO - -------------------------------------------------
2024-01-19 08:01:01,946 - distributed.core - INFO - Starting established connection to tcp://10.3.88.12:42763
2024-01-19 08:01:01,949 - distributed.worker - INFO -         Registered to:     tcp://10.3.88.12:42763
2024-01-19 08:01:01,949 - distributed.worker - INFO - -------------------------------------------------
2024-01-19 08:01:01,950 - distributed.core - INFO - Starting established connection to tcp://10.3.88.12:42763
2024-01-19 08:04:05,983 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-01-19 08:04:05,984 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
Warning (not error because allow_undefined_stereo=True): RDMol has unspecified stereochemistry. Bonds with undefined stereochemistry are:
 - Bond 1 (atoms 1-2 of element (C-C)

/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
Warning (not error because allow_undefined_stereo=True): RDMol has unspecified stereochemistry. Bonds with undefined stereochemistry are:
 - Bond 1 (atoms 1-2 of element (C-C)

/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/__init__.py:55: UserWarning: Dependency not satisfied, torchani.ase will not be available
  warnings.warn("Dependency not satisfied, torchani.ase will not be available")
Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/__init__.py:55: UserWarning: Dependency not satisfied, torchani.ase will not be available
  warnings.warn("Dependency not satisfied, torchani.ase will not be available")
Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.
TIME changed dir: 0.0s
TIME changed dir: 0.0s
Generated 20 conformers. 
Removed 10 conformers. 
Generated 21 conformers. 
Removed 14 conformers. 
using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
failed to equip `nnpops` with error: No module named 'NNPOps'
Optimising conformer:   0%|                              | 0/10 [00:00<?, ?it/s][W BinaryOps.cpp:601] Warning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (function operator())
Optimising conformer:  10%|██▏                   | 1/10 [00:03<00:34,  3.80s/it]TIME changed dir: 0.0s
TIME changed dir: 0.0s
Generated 36 conformers. 
Generated 13 conformers. 
Removed 9 conformers. 
Removed 11 conformers. 
using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
failed to equip `nnpops` with error: No module named 'NNPOps'
Optimising conformer:   0%|                              | 0/25 [00:00<?, ?it/s]Optimising conformer:  20%|████▍                 | 2/10 [00:05<00:22,  2.78s/it][W BinaryOps.cpp:601] Warning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (function operator())
Optimising conformer:  30%|██████▌               | 3/10 [00:08<00:19,  2.81s/it]Optimising conformer:   4%|▉                     | 1/25 [00:04<01:43,  4.33s/it]Optimising conformer:  40%|████████▊             | 4/10 [00:12<00:18,  3.03s/it]Optimising conformer:   8%|█▊                    | 2/25 [00:08<01:32,  4.03s/it]Optimising conformer:  50%|███████████           | 5/10 [00:15<00:15,  3.00s/it]Optimising conformer:  12%|██▋                   | 3/25 [00:11<01:17,  3.54s/it]Optimising conformer:  60%|█████████████▏        | 6/10 [00:17<00:10,  2.69s/it]Optimising conformer:  70%|███████████████▍      | 7/10 [00:19<00:08,  2.72s/it]Optimising conformer:  16%|███▌                  | 4/25 [00:14<01:15,  3.59s/it]using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
failed to equip `nnpops` with error: No module named 'NNPOps'

Optimising conformer:   0%|                               | 0/7 [00:00<?, ?it/s][AOptimising conformer:  80%|█████████████████▌    | 8/10 [00:22<00:05,  2.58s/it]Optimising conformer:  20%|████▍                 | 5/25 [00:18<01:10,  3.52s/it]Optimising conformer:  90%|███████████████████▊  | 9/10 [00:25<00:02,  2.76s/it]
Optimising conformer:  14%|███▎                   | 1/7 [00:05<00:34,  5.80s/it][AOptimising conformer:  24%|█████▎                | 6/25 [00:21<01:05,  3.47s/it]Optimising conformer: 100%|█████████████████████| 10/10 [00:27<00:00,  2.65s/it]Optimising conformer: 100%|█████████████████████| 10/10 [00:27<00:00,  2.77s/it]

Optimising conformer:  29%|██████▌                | 2/7 [00:07<00:17,  3.57s/it][AOptimising conformer:  28%|██████▏               | 7/25 [00:24<00:58,  3.27s/it]
Optimising conformer:  43%|█████████▊             | 3/7 [00:11<00:13,  3.50s/it][AOptimising conformer:  32%|███████               | 8/25 [00:27<00:55,  3.27s/it]
Optimising conformer:  57%|█████████████▏         | 4/7 [00:12<00:08,  2.80s/it][A
Optimising conformer:  71%|████████████████▍      | 5/7 [00:15<00:05,  2.85s/it][AOptimising conformer:  36%|███████▉              | 9/25 [00:31<00:55,  3.48s/it]Optimising conformer:  40%|████████▍            | 10/25 [00:35<00:53,  3.57s/it]
Optimising conformer:  86%|███████████████████▋   | 6/7 [00:23<00:04,  4.43s/it][AOptimising conformer:  44%|█████████▏           | 11/25 [00:38<00:49,  3.50s/it]
Optimising conformer: 100%|███████████████████████| 7/7 [00:24<00:00,  3.45s/it][AOptimising conformer: 100%|███████████████████████| 7/7 [00:24<00:00,  3.54s/it]
Optimising conformer:  48%|██████████           | 12/25 [00:42<00:46,  3.55s/it]Optimising conformer:  52%|██████████▉          | 13/25 [00:44<00:38,  3.21s/it]using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
failed to equip `nnpops` with error: No module named 'NNPOps'

Optimising conformer:   0%|                               | 0/4 [00:00<?, ?it/s][AOptimising conformer:  56%|███████████▊         | 14/25 [00:47<00:33,  3.03s/it]
Optimising conformer:  25%|█████▊                 | 1/4 [00:02<00:07,  2.54s/it][A
Optimising conformer:  50%|███████████▌           | 2/4 [00:04<00:04,  2.05s/it][AOptimising conformer:  60%|████████████▌        | 15/25 [00:50<00:31,  3.11s/it]Optimising conformer:  64%|█████████████▍       | 16/25 [00:53<00:27,  3.10s/it]
Optimising conformer:  75%|█████████████████▎     | 3/4 [00:07<00:02,  2.81s/it][AOptimising conformer:  68%|██████████████▎      | 17/25 [00:56<00:22,  2.86s/it]
Optimising conformer: 100%|███████████████████████| 4/4 [00:11<00:00,  3.05s/it][AOptimising conformer: 100%|███████████████████████| 4/4 [00:11<00:00,  2.84s/it]
Optimising conformer:  72%|███████████████      | 18/25 [00:59<00:20,  2.88s/it]Optimising conformer:  76%|███████████████▉     | 19/25 [01:03<00:20,  3.36s/it]Optimising conformer:  80%|████████████████▊    | 20/25 [01:05<00:14,  3.00s/it]Optimising conformer:  84%|█████████████████▋   | 21/25 [01:36<00:45, 11.33s/it]Optimising conformer:  88%|██████████████████▍  | 22/25 [01:38<00:25,  8.53s/it]Optimising conformer:  92%|███████████████████▎ | 23/25 [01:43<00:14,  7.35s/it]Optimising conformer:  96%|████████████████████▏| 24/25 [01:45<00:05,  6.00s/it]Optimising conformer: 100%|█████████████████████| 25/25 [01:48<00:00,  4.96s/it]Optimising conformer: 100%|█████████████████████| 25/25 [01:48<00:00,  4.34s/it]
2024-01-19 09:24:30,931 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/tornado/iostream.py", line 1116, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/worker.py", line 1237, in heartbeat
    response = await retry_operation(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry_operation
    return await retry(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/utils_comm.py", line 413, in retry
    return await coro()
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 1227, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 986, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/comm/tcp.py", line 241, in read
    convert_stream_closed_error(self, e)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.3.89.125:44902 remote=tcp://10.3.88.12:42763>: TimeoutError: [Errno 110] Connection timed out
2024-01-19 09:24:30,995 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/tornado/iostream.py", line 1116, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/worker.py", line 1237, in heartbeat
    response = await retry_operation(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry_operation
    return await retry(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/utils_comm.py", line 413, in retry
    return await coro()
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 1227, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 986, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/comm/tcp.py", line 241, in read
    convert_stream_closed_error(self, e)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.3.89.125:44904 remote=tcp://10.3.88.12:42763>: TimeoutError: [Errno 110] Connection timed out
2024-01-19 09:24:40,603 - distributed.core - INFO - Connection to tcp://10.3.88.12:42763 has been closed.
2024-01-19 09:24:40,603 - distributed.core - INFO - Connection to tcp://10.3.88.12:42763 has been closed.
2024-01-19 09:24:40,605 - distributed.worker - INFO - Stopping worker at tcp://10.3.89.125:36581. Reason: worker-handle-scheduler-connection-broken
2024-01-19 09:24:40,605 - distributed.worker - INFO - Stopping worker at tcp://10.3.89.125:36770. Reason: worker-handle-scheduler-connection-broken
2024-01-19 09:24:40,610 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.3.89.125:33632'. Reason: worker-handle-scheduler-connection-broken
2024-01-19 09:24:40,611 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.3.89.125:38841'. Reason: worker-handle-scheduler-connection-broken
2024-01-19 09:24:40,625 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 1389, in _connect
    comm = await connect(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/comm/core.py", line 291, in connect
    comm = await asyncio.wait_for(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/worker.py", line 1237, in heartbeat
    response = await retry_operation(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry_operation
    return await retry(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/utils_comm.py", line 413, in retry
    return await coro()
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 1224, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 1468, in connect
    return await connect_attempt
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 1412, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-01-19 09:24:40,624 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 1389, in _connect
    comm = await connect(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/comm/core.py", line 291, in connect
    comm = await asyncio.wait_for(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/worker.py", line 1237, in heartbeat
    response = await retry_operation(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry_operation
    return await retry(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/utils_comm.py", line 413, in retry
    return await coro()
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 1224, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 1468, in connect
    return await connect_attempt
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 1412, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-01-19 09:24:40,630 - distributed.nanny - INFO - Worker closed
2024-01-19 09:24:40,630 - distributed.nanny - INFO - Worker closed
2024-01-19 09:24:42,639 - distributed.nanny - ERROR - Worker process died unexpectedly
TIME Completed the molecule generation in 77.3s.
TIME Completed the molecule generation in 83.7s.
TIME Completed the molecule generation in 104.0s.
TIME Completed the molecule generation in 160.1s.
2024-01-19 09:24:45,881 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.3.89.125:33632'. Reason: nanny-close-gracefully
2024-01-19 09:24:46,009 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.3.89.125:38841'. Reason: nanny-close-gracefully
2024-01-19 09:24:46,010 - distributed.dask_worker - INFO - End worker
