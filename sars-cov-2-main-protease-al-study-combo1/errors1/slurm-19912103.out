hostname sb042.cluster
ipconfig 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: enp4s0f0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 9000 qdisc mq state UP group default qlen 1000 link/ether a0:8c:f8:74:c8:f0 brd ff:ff:ff:ff:ff:ff inet 10.3.81.122/22 brd 10.3.83.255 scope global enp4s0f0 valid_lft forever preferred_lft forever inet6 fe80::a28c:f8ff:fe74:c8f0/64 scope link valid_lft forever preferred_lft forever 3: enp4s0f1: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether a0:8c:f8:74:c8:f1 brd ff:ff:ff:ff:ff:ff 4: enp4s0f2: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether a0:8c:f8:74:c8:f2 brd ff:ff:ff:ff:ff:ff 5: enp4s0f3: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether a0:8c:f8:74:c8:f3 brd ff:ff:ff:ff:ff:ff 6: ib0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 4092 qdisc pfifo_fast state UP group default qlen 256 link/infiniband 80:00:00:29:fe:80:00:00:00:00:00:00:38:bc:01:03:00:4c:f6:90 brd 00:ff:ff:ff:ff:12:40:1b:ff:ff:00:00:00:00:00:00:ff:ff:ff:ff inet 10.3.89.122/22 brd 10.3.91.255 scope global ib0 valid_lft forever preferred_lft forever inet 10.3.97.122/22 brd 10.3.99.255 scope global ib0:1 valid_lft forever preferred_lft forever inet6 fe80::3abc:103:4c:f690/64 scope link valid_lft forever preferred_lft forever 7: ib1: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 4092 qdisc pfifo_fast state DOWN group default qlen 256 link/infiniband 80:00:00:29:fe:80:00:00:00:00:00:00:38:bc:01:03:00:4c:f6:91 brd 00:ff:ff:ff:ff:12:40:1b:ff:ff:00:00:00:00:00:00:ff:ff:ff:ff
2024-02-01 01:52:11,602 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.3.89.122:37684'
2024-02-01 01:55:48,092 - distributed.diskutils - INFO - Found stale lock file and directory '/scratch/dask-worker-space/worker-aznoic6r', purging
2024-02-01 01:56:14,924 - distributed.worker - INFO -       Start worker at:    tcp://10.3.89.122:42572
2024-02-01 01:56:14,925 - distributed.worker - INFO -          Listening to:    tcp://10.3.89.122:42572
2024-02-01 01:56:14,925 - distributed.worker - INFO -           Worker name:             SLURMCluster-6
2024-02-01 01:56:14,925 - distributed.worker - INFO -          dashboard at:          10.3.89.122:33428
2024-02-01 01:56:14,925 - distributed.worker - INFO - Waiting to connect to:     tcp://10.3.88.11:37020
2024-02-01 01:56:14,925 - distributed.worker - INFO - -------------------------------------------------
2024-02-01 01:56:14,925 - distributed.worker - INFO -               Threads:                          2
2024-02-01 01:56:14,925 - distributed.worker - INFO -                Memory:                  20.49 GiB
2024-02-01 01:56:14,925 - distributed.worker - INFO -       Local Directory: /scratch/dask-worker-space/worker-4_p6y3i5
2024-02-01 01:56:14,926 - distributed.worker - INFO - -------------------------------------------------
2024-02-01 01:56:14,987 - distributed.worker - INFO -         Registered to:     tcp://10.3.88.11:37020
2024-02-01 01:56:14,987 - distributed.worker - INFO - -------------------------------------------------
2024-02-01 01:56:14,988 - distributed.core - INFO - Starting established connection to tcp://10.3.88.11:37020
2024-02-01 01:56:53,360 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 01:56:53,360 - distributed.core - INFO - Event loop was unresponsive in Nanny for 5.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 01:57:57,217 - distributed.core - INFO - Event loop was unresponsive in Nanny for 59.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 01:57:57,217 - distributed.core - INFO - Event loop was unresponsive in Worker for 61.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 01:58:11,293 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 01:58:11,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 01:58:39,807 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 01:58:39,807 - distributed.core - INFO - Event loop was unresponsive in Nanny for 11.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 01:59:02,381 - distributed.core - INFO - Event loop was unresponsive in Nanny for 4.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 01:59:02,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 01:59:21,371 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 01:59:21,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:02:11,538 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:02:11,535 - distributed.core - INFO - Event loop was unresponsive in Nanny for 93.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:02:37,500 - distributed.core - INFO - Event loop was unresponsive in Nanny for 8.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:02:37,501 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:03:05,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:03:05,629 - distributed.core - INFO - Event loop was unresponsive in Nanny for 7.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:03:05,651 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:05:06,733 - distributed.core - INFO - Event loop was unresponsive in Nanny for 73.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:05:06,738 - distributed.core - INFO - Event loop was unresponsive in Nanny for 5.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:05:07,067 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:05:34,958 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:05:54,518 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:05:54,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:06:14,677 - distributed.core - INFO - Event loop was unresponsive in Nanny for 5.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:06:14,677 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:06:30,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:07:42,973 - distributed.core - INFO - Event loop was unresponsive in Nanny for 47.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:09:41,683 - distributed.core - INFO - Event loop was unresponsive in Nanny for 23.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:10:46,610 - distributed.core - INFO - Event loop was unresponsive in Nanny for 17.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:10:56,598 - distributed.core - INFO - Event loop was unresponsive in Worker for 266.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:10:56,598 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 266.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:11:12,497 - distributed.core - INFO - Event loop was unresponsive in Nanny for 13.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:11:12,574 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:11:12,574 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 14.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
2024-02-01 02:11:21,950 [WARNING] [rdkit_wrapper.py:3213] openff.toolkit.utils.rdkit_wrapper: Warning (not error because allow_undefined_stereo=True): RDMol has unspecified stereochemistry. Undefined chiral centers are:
 - Atom C (index 1)
 - Atom C (index 5)

2024-02-01 02:11:25,379 [WARNING] [rdkit_wrapper.py:3213] openff.toolkit.utils.rdkit_wrapper: Warning (not error because allow_undefined_stereo=True): RDMol has unspecified stereochemistry. Undefined chiral centers are:
 - Atom C (index 1)
 - Atom C (index 5)

2024-02-01 02:11:42,905 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:11:42,905 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:11:42,905 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 3.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:12:10,562 - distributed.core - INFO - Event loop was unresponsive in Nanny for 11.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:12:10,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:12:10,562 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 11.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:12:50,371 - distributed.core - INFO - Event loop was unresponsive in Nanny for 10.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:12:50,374 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:12:50,374 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 12.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:15:15,769 - distributed.core - INFO - Event loop was unresponsive in Nanny for 135.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:15:15,780 - distributed.core - INFO - Event loop was unresponsive in Worker for 135.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:15:15,780 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 135.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/__init__.py:55: UserWarning: Dependency not satisfied, torchani.ase will not be available
  warnings.warn("Dependency not satisfied, torchani.ase will not be available")
2024-02-01 02:15:37,626 [WARNING] [__init__.py:5] root: Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.
2024-02-01 02:15:47,621 - distributed.worker - WARNING - Compute Failed
Key:       evaluate-855deefc-02bf-4d83-8ddd-6597c0f4bf34
Function:  evaluate
args:      (<rdkit.Chem.rdchem.Mol object at 0x2b1758d26630>, 6, 'C(C(N(C(=O)C(C([H])([H])[H])(c1c(c(c(nc1[H])[H])[H])[H])[H])[H])(c1c(c2c(c(c(c(c2n1[H])[H])[H])[H])[H])[H])[H])([H])([H])[H]', '/mnt/storage/nobackup/nmb1063/code/gal/sars-cov-2-main-protease-al-study-combo1/rec_final.pdb', '/nobackup/nmb1063/sars-fegrow/gnina')
kwargs:    {}
Exception: 'RuntimeError("Can\'t redefine method: forward on class: __torch__.torchani.aev.AEVComputer (of Python compilation unit at: 0x2b1757c764e0)")'

2024-02-01 02:15:47,621 [WARNING] [worker.py:2352] distributed.worker: Compute Failed
Key:       evaluate-855deefc-02bf-4d83-8ddd-6597c0f4bf34
Function:  evaluate
args:      (<rdkit.Chem.rdchem.Mol object at 0x2b1758d26630>, 6, 'C(C(N(C(=O)C(C([H])([H])[H])(c1c(c(c(nc1[H])[H])[H])[H])[H])[H])(c1c(c2c(c(c(c(c2n1[H])[H])[H])[H])[H])[H])[H])([H])([H])[H]', '/mnt/storage/nobackup/nmb1063/code/gal/sars-cov-2-main-protease-al-study-combo1/rec_final.pdb', '/nobackup/nmb1063/sars-fegrow/gnina')
kwargs:    {}
Exception: 'RuntimeError("Can\'t redefine method: forward on class: __torch__.torchani.aev.AEVComputer (of Python compilation unit at: 0x2b1757c764e0)")'

2024-02-01 02:15:49,906 - distributed.utils_perf - INFO - full garbage collection released 14.97 MiB from 236390 reference cycles (threshold: 9.54 MiB)
2024-02-01 02:15:49,906 [INFO] [utils_perf.py:198] distributed.utils_perf: full garbage collection released 14.97 MiB from 236390 reference cycles (threshold: 9.54 MiB)
TIME changed dir: 0.0s
TIME changed dir: 0.0s
Generated 14 conformers. 
Removed 11 conformers. 
Generated 29 conformers. 
Removed 27 conformers. 
using ani2x
using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
failed to equip `nnpops` with error: No module named 'NNPOps'
failed to equip `nnpops` with error: No module named 'NNPOps'
TIME changed dir: 0.0s
Generated 14 conformers. 
Optimising conformer:   0%|                               | 0/3 [00:00<?, ?it/s][W BinaryOps.cpp:601] Warning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (function operator())
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
2024-02-01 02:16:11,381 - distributed.core - INFO - Event loop was unresponsive in Nanny for 11.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:16:11,381 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:16:11,381 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 11.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
Optimising conformer:  33%|███████▋               | 1/3 [00:24<00:48, 24.04s/it]Optimising conformer:  67%|███████████████▎       | 2/3 [00:26<00:11, 11.25s/it]Optimising conformer: 100%|███████████████████████| 3/3 [00:28<00:00,  7.25s/it]Optimising conformer: 100%|███████████████████████| 3/3 [00:28<00:00,  9.61s/it]
Removed 7 conformers. 
using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
failed to equip `nnpops` with error: No module named 'NNPOps'
Optimising conformer:   0%|                               | 0/7 [00:00<?, ?it/s]Optimising conformer:  14%|███▎                   | 1/7 [00:02<00:16,  2.74s/it]/mnt/storage/nobackup/nmb1063/code/gal/sars-cov-2-main-protease-al-study-combo1/rsearcher.py:89: UserWarning: The ligand was an array (SDF?). Using the first frame. 
  warnings.warn("The ligand was an array (SDF?). Using the first frame. ")
Optimising conformer:  29%|██████▌                | 2/7 [00:04<00:09,  1.99s/it]Optimising conformer:  43%|█████████▊             | 3/7 [00:05<00:06,  1.74s/it]Optimising conformer:  57%|█████████████▏         | 4/7 [00:07<00:05,  1.76s/it]Optimising conformer:  71%|████████████████▍      | 5/7 [00:09<00:03,  1.72s/it]Optimising conformer:  86%|███████████████████▋   | 6/7 [00:10<00:01,  1.67s/it]2024-02-01 02:16:40,111 [WARNING] [rdkit_wrapper.py:3213] openff.toolkit.utils.rdkit_wrapper: Warning (not error because allow_undefined_stereo=True): RDMol has unspecified stereochemistry. Bonds with undefined stereochemistry are:
 - Bond 2 (atoms 2-3 of element (C-C)

/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
2024-02-01 02:16:42,360 [WARNING] [rdkit_wrapper.py:3213] openff.toolkit.utils.rdkit_wrapper: Warning (not error because allow_undefined_stereo=True): RDMol has unspecified stereochemistry. Bonds with undefined stereochemistry are:
 - Bond 2 (atoms 2-3 of element (C-C)

Optimising conformer: 100%|███████████████████████| 7/7 [00:15<00:00,  2.66s/it]Optimising conformer: 100%|███████████████████████| 7/7 [00:15<00:00,  2.19s/it]
2024-02-01 02:18:03,808 - distributed.core - INFO - Event loop was unresponsive in Nanny for 63.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:18:03,808 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:18:03,808 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 69.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:18:11,919 - distributed.core - INFO - Event loop was unresponsive in Nanny for 8.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:18:11,934 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:18:11,934 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 8.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:18:29,358 - distributed.core - INFO - Event loop was unresponsive in Nanny for 9.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:18:29,369 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:18:29,369 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 9.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/mnt/storage/nobackup/nmb1063/code/gal/sars-cov-2-main-protease-al-study-combo1/rsearcher.py:89: UserWarning: The ligand was an array (SDF?). Using the first frame. 
  warnings.warn("The ligand was an array (SDF?). Using the first frame. ")
2024-02-01 02:18:42,075 [WARNING] [rdkit_wrapper.py:3213] openff.toolkit.utils.rdkit_wrapper: Warning (not error because allow_undefined_stereo=True): RDMol has unspecified stereochemistry. Undefined chiral centers are:
 - Atom N (index 7)

/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
2024-02-01 02:18:43,860 [WARNING] [rdkit_wrapper.py:3213] openff.toolkit.utils.rdkit_wrapper: Warning (not error because allow_undefined_stereo=True): RDMol has unspecified stereochemistry. Undefined chiral centers are:
 - Atom N (index 7)

2024-02-01 02:19:42,154 - distributed.core - INFO - Event loop was unresponsive in Nanny for 52.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:19:42,158 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
TIME Completed the molecule generation in 339.4s.
TIME changed dir: 0.0s
Generated 27 conformers. 
Removed 15 conformers. 
TIME Completed the molecule generation in 169.9s.
TIME changed dir: 0.0s
Generated 26 conformers. 
Removed 18 conformers. 
using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
failed to equip `nnpops` with error: No module named 'NNPOps'
2024-02-01 02:19:42,158 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 52.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
Optimising conformer:   0%|                               | 0/8 [00:00<?, ?it/s]2024-02-01 02:21:01,327 - distributed.core - INFO - Event loop was unresponsive in Nanny for 79.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:21:01,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:21:01,354 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 79.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
failed to equip `nnpops` with error: No module named 'NNPOps'

Optimising conformer:   0%|                              | 0/12 [00:00<?, ?it/s][AOptimising conformer:  12%|██▉                    | 1/8 [00:06<00:43,  6.18s/it]
Optimising conformer:   8%|█▊                    | 1/12 [00:05<00:57,  5.21s/it][AOptimising conformer:  25%|█████▊                 | 2/8 [00:09<00:28,  4.74s/it]
Optimising conformer:  17%|███▋                  | 2/12 [00:10<00:51,  5.14s/it][A
Optimising conformer:  25%|█████▌                | 3/12 [00:12<00:34,  3.84s/it][AOptimising conformer:  38%|████████▋              | 3/8 [00:15<00:26,  5.28s/it]Optimising conformer:  50%|███████████▌           | 4/8 [00:17<00:16,  4.01s/it]
Optimising conformer:  33%|███████▎              | 4/12 [00:16<00:32,  4.05s/it][AOptimising conformer:  62%|██████████████▍        | 5/8 [00:26<00:17,  5.82s/it]Optimising conformer:  75%|█████████████████▎     | 6/8 [00:32<00:11,  5.88s/it]Optimising conformer:  88%|████████████████████▏  | 7/8 [00:34<00:04,  4.62s/it]Optimising conformer: 100%|███████████████████████| 8/8 [00:40<00:00,  4.78s/it]Optimising conformer: 100%|███████████████████████| 8/8 [00:40<00:00,  5.01s/it]
/mnt/storage/nobackup/nmb1063/code/gal/sars-cov-2-main-protease-al-study-combo1/rsearcher.py:89: UserWarning: The ligand was an array (SDF?). Using the first frame. 
  warnings.warn("The ligand was an array (SDF?). Using the first frame. ")
2024-02-01 02:22:20,381 - distributed.core - INFO - Event loop was unresponsive in Nanny for 9.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:22:20,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:22:20,383 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 9.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.

Optimising conformer:  42%|█████████▏            | 5/12 [01:16<02:47, 23.94s/it][A
Optimising conformer:  50%|███████████           | 6/12 [01:20<01:43, 17.18s/it][A
Optimising conformer:  58%|████████████▊         | 7/12 [01:22<01:00, 12.18s/it][A
Optimising conformer:  67%|██████████████▋       | 8/12 [01:24<00:36,  9.12s/it][A
Optimising conformer:  75%|████████████████▌     | 9/12 [01:27<00:21,  7.22s/it][A
Optimising conformer:  83%|█████████████████▌   | 10/12 [01:31<00:12,  6.17s/it][A
Optimising conformer:  92%|███████████████████▎ | 11/12 [01:35<00:05,  5.34s/it][A
Optimising conformer: 100%|█████████████████████| 12/12 [01:37<00:00,  4.48s/it][AOptimising conformer: 100%|█████████████████████| 12/12 [01:37<00:00,  8.13s/it]
2024-02-01 02:24:01,787 - distributed.core - INFO - Event loop was unresponsive in Nanny for 71.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:24:01,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 75.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:24:01,870 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 75.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:24:18,640 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:24:18,640 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
2024-02-01 02:24:48,499 - distributed.core - INFO - Event loop was unresponsive in Nanny for 18.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:24:48,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:24:48,500 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 19.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:25:05,836 - distributed.core - INFO - Event loop was unresponsive in Nanny for 5.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:25:05,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:25:05,836 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
TIME Completed the molecule generation in 198.6s.
TIME Completed the molecule generation in 447.3s.
TIME changed dir: 0.0s
TIME changed dir: 0.0s
Generated 22 conformers. 
Removed 10 conformers. 
Generated 30 conformers. 
Removed 15 conformers. 
using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
failed to equip `nnpops` with error: No module named 'NNPOps'
failed to equip `nnpops` with error: No module named 'NNPOps'
Optimising conformer:   0%|                              | 0/15 [00:00<?, ?it/s]
Optimising conformer:   0%|                              | 0/12 [00:00<?, ?it/s][A
Optimising conformer:   8%|█▊                    | 1/12 [00:02<00:29,  2.69s/it][AOptimising conformer:   7%|█▍                    | 1/15 [00:04<01:08,  4.87s/it]
Optimising conformer:  17%|███▋                  | 2/12 [00:06<00:30,  3.09s/it][A
Optimising conformer:  25%|█████▌                | 3/12 [00:07<00:22,  2.46s/it][AOptimising conformer:  13%|██▉                   | 2/15 [00:08<00:50,  3.91s/it]
Optimising conformer:  33%|███████▎              | 4/12 [00:09<00:16,  2.09s/it][AOptimising conformer:  20%|████▍                 | 3/15 [00:10<00:37,  3.15s/it]
Optimising conformer:  42%|█████████▏            | 5/12 [00:11<00:15,  2.20s/it][AOptimising conformer:  27%|█████▊                | 4/15 [00:12<00:31,  2.90s/it]
Optimising conformer:  50%|███████████           | 6/12 [00:13<00:12,  2.09s/it][AOptimising conformer:  33%|███████▎              | 5/15 [00:16<00:32,  3.27s/it]
Optimising conformer:  58%|████████████▊         | 7/12 [00:16<00:12,  2.42s/it][AOptimising conformer:  40%|████████▊             | 6/15 [00:18<00:25,  2.86s/it]
Optimising conformer:  67%|██████████████▋       | 8/12 [00:18<00:09,  2.27s/it][A
Optimising conformer:  75%|████████████████▌     | 9/12 [00:20<00:06,  2.13s/it][AOptimising conformer:  47%|██████████▎           | 7/15 [00:20<00:20,  2.62s/it]
Optimising conformer:  83%|█████████████████▌   | 10/12 [00:22<00:03,  1.99s/it][AOptimising conformer:  53%|███████████▋          | 8/15 [00:23<00:17,  2.43s/it]
Optimising conformer:  92%|███████████████████▎ | 11/12 [00:23<00:01,  1.85s/it][AOptimising conformer:  60%|█████████████▏        | 9/15 [00:25<00:14,  2.37s/it]
Optimising conformer: 100%|█████████████████████| 12/12 [00:26<00:00,  2.05s/it][AOptimising conformer: 100%|█████████████████████| 12/12 [00:26<00:00,  2.18s/it]
Optimising conformer:  67%|██████████████       | 10/15 [00:28<00:13,  2.74s/it]Optimising conformer:  73%|███████████████▍     | 11/15 [00:31<00:11,  2.78s/it]Optimising conformer:  80%|████████████████▊    | 12/15 [00:35<00:09,  3.02s/it]/mnt/storage/nobackup/nmb1063/code/gal/sars-cov-2-main-protease-al-study-combo1/rsearcher.py:89: UserWarning: The ligand was an array (SDF?). Using the first frame. 
  warnings.warn("The ligand was an array (SDF?). Using the first frame. ")
Optimising conformer:  87%|██████████████████▏  | 13/15 [00:37<00:05,  2.93s/it]Optimising conformer:  93%|███████████████████▌ | 14/15 [00:40<00:02,  2.91s/it]Optimising conformer: 100%|█████████████████████| 15/15 [00:42<00:00,  2.65s/it]Optimising conformer: 100%|█████████████████████| 15/15 [00:42<00:00,  2.86s/it]
2024-02-01 02:26:14,225 [WARNING] [rdkit_wrapper.py:3213] openff.toolkit.utils.rdkit_wrapper: Warning (not error because allow_undefined_stereo=True): RDMol has unspecified stereochemistry. Undefined chiral centers are:
 - Atom C (index 20)
 - Atom C (index 31)

2024-02-01 02:26:58,741 - distributed.core - INFO - Event loop was unresponsive in Nanny for 37.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:27:15,661 - distributed.core - INFO - Event loop was unresponsive in Nanny for 14.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:28:05,476 - distributed.core - INFO - Event loop was unresponsive in Nanny for 49.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:28:05,476 - distributed.core - INFO - Event loop was unresponsive in Worker for 110.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:28:05,476 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 110.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/parmed/structure.py:1775: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.
  coords = np.array(value, dtype=np.float64, copy=False, subok=True)
2024-02-01 02:28:08,407 [WARNING] [rdkit_wrapper.py:3213] openff.toolkit.utils.rdkit_wrapper: Warning (not error because allow_undefined_stereo=True): RDMol has unspecified stereochemistry. Undefined chiral centers are:
 - Atom C (index 20)
 - Atom C (index 31)

2024-02-01 02:28:26,870 - distributed.core - INFO - Event loop was unresponsive in Nanny for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:28:26,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:28:26,870 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:29:14,711 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:29:14,711 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 3.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:30:39,823 - distributed.core - INFO - Event loop was unresponsive in Worker for 62.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:30:39,822 - distributed.core - INFO - Event loop was unresponsive in Nanny for 58.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:30:39,823 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 62.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:31:19,647 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:31:19,647 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 8.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:31:26,743 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:31:26,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:31:26,775 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:32:57,812 - distributed.core - INFO - Event loop was unresponsive in Nanny for 56.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:32:57,818 - distributed.core - INFO - Event loop was unresponsive in Worker for 62.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:32:57,818 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 62.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:34:06,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:34:06,868 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 45.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:35:19,825 - distributed.core - INFO - Event loop was unresponsive in Nanny for 117.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:35:20,479 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:35:20,479 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 73.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:36:44,886 - distributed.core - INFO - Event loop was unresponsive in Nanny for 83.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:36:45,195 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:36:45,195 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 83.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
TIME Completed the molecule generation in 110.9s.
TIME changed dir: 0.0s
Generated 45 conformers. 
Removed 38 conformers. 
TIME Completed the molecule generation in 235.1s.
using ani2x
/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/torchani/resources/
failed to equip `nnpops` with error: No module named 'NNPOps'
Optimising conformer:   0%|                               | 0/7 [00:00<?, ?it/s]Optimising conformer:  14%|███▎                   | 1/7 [00:05<00:31,  5.31s/it]Optimising conformer:  29%|██████▌                | 2/7 [00:09<00:22,  4.52s/it]Optimising conformer:  43%|█████████▊             | 3/7 [00:14<00:20,  5.02s/it]Optimising conformer:  57%|█████████████▏         | 4/7 [00:18<00:13,  4.54s/it]Optimising conformer:  71%|████████████████▍      | 5/7 [00:24<00:10,  5.05s/it]Optimising conformer:  86%|███████████████████▋   | 6/7 [00:29<00:04,  4.93s/it]Optimising conformer: 100%|███████████████████████| 7/7 [00:38<00:00,  6.28s/it]Optimising conformer: 100%|███████████████████████| 7/7 [00:38<00:00,  5.49s/it]
2024-02-01 02:38:02,826 - distributed.core - INFO - Event loop was unresponsive in Nanny for 20.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:38:02,826 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:38:02,826 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 20.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:38:56,388 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:38:56,388 - distributed.core - INFO - Event loop was unresponsive in Nanny for 14.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:38:56,388 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 14.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/mnt/storage/nobackup/nmb1063/code/gal/sars-cov-2-main-protease-al-study-combo1/rsearcher.py:89: UserWarning: The ligand was an array (SDF?). Using the first frame. 
  warnings.warn("The ligand was an array (SDF?). Using the first frame. ")
2024-02-01 02:39:16,376 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:39:16,376 - distributed.core - INFO - Event loop was unresponsive in Nanny for 4.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:39:16,376 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:39:35,853 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:39:35,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:39:35,853 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 3.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:42:04,180 - distributed.core - INFO - Event loop was unresponsive in Nanny for 133.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:42:04,181 - distributed.core - INFO - Event loop was unresponsive in Worker for 137.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:42:04,181 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 137.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:42:19,228 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:42:19,228 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 4.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:45:05,002 - distributed.core - INFO - Event loop was unresponsive in Nanny for 72.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:45:05,004 - distributed.core - INFO - Event loop was unresponsive in Worker for 72.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:45:05,004 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 72.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:46:08,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:46:08,828 - distributed.core - INFO - Event loop was unresponsive in Nanny for 56.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:46:08,828 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 56.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:47:14,762 - distributed.core - INFO - Event loop was unresponsive in Worker for 62.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:47:14,762 - distributed.core - INFO - Event loop was unresponsive in Nanny for 62.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:47:14,762 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 62.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:47:14,792 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/tornado/iostream.py", line 1116, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/worker.py", line 1237, in heartbeat
    response = await retry_operation(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry_operation
    return await retry(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/utils_comm.py", line 413, in retry
    return await coro()
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 1227, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 986, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/comm/tcp.py", line 241, in read
    convert_stream_closed_error(self, e)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.3.89.122:56868 remote=tcp://10.3.88.11:37020>: ConnectionResetError: [Errno 104] Connection reset by peer
2024-02-01 02:47:14,792 [ERROR] [worker.py:1274] distributed.worker: Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/tornado/iostream.py", line 1116, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/worker.py", line 1237, in heartbeat
    response = await retry_operation(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry_operation
    return await retry(
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/utils_comm.py", line 413, in retry
    return await coro()
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 1227, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/core.py", line 986, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/comm/tcp.py", line 241, in read
    convert_stream_closed_error(self, e)
  File "/mnt/storage/nobackup/nmb1063/mamba/envs/fegrow/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.3.89.122:56868 remote=tcp://10.3.88.11:37020>: ConnectionResetError: [Errno 104] Connection reset by peer
2024-02-01 02:49:04,081 - distributed.core - INFO - Event loop was unresponsive in Nanny for 101.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:49:04,082 - distributed.core - INFO - Event loop was unresponsive in Worker for 101.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:49:04,082 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 101.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:49:43,998 - distributed.core - INFO - Event loop was unresponsive in Nanny for 20.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:49:43,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:49:43,999 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 20.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:50:33,660 - distributed.core - INFO - Event loop was unresponsive in Nanny for 30.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:50:33,662 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:50:33,662 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 30.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:51:17,066 - distributed.core - INFO - Event loop was unresponsive in Nanny for 13.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:51:17,101 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:51:17,101 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 43.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:51:38,711 - distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:51:38,713 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:51:38,713 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:52:41,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 48.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:52:41,270 - distributed.core - INFO - Event loop was unresponsive in Nanny for 48.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:52:41,270 [INFO] [core.py:595] distributed.core: Event loop was unresponsive in Worker for 48.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-02-01 02:52:43,990 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://10.3.89.122:42572'. Shutting down.
2024-02-01 02:52:43,990 [ERROR] [worker.py:1260] distributed.worker: Scheduler was unaware of this worker 'tcp://10.3.89.122:42572'. Shutting down.
2024-02-01 02:52:43,990 - distributed.worker - INFO - Stopping worker at tcp://10.3.89.122:42572. Reason: worker-close
2024-02-01 02:52:43,990 [INFO] [worker.py:1535] distributed.worker: Stopping worker at tcp://10.3.89.122:42572. Reason: worker-close
2024-02-01 02:52:43,992 - distributed.core - INFO - Connection to tcp://10.3.88.11:37020 has been closed.
2024-02-01 02:52:43,992 [INFO] [core.py:877] distributed.core: Connection to tcp://10.3.88.11:37020 has been closed.
2024-02-01 02:52:43,996 - distributed.nanny - INFO - Worker closed
2024-02-01 02:52:43,996 [INFO] [nanny.py:945] distributed.nanny: Worker closed
slurmstepd: error: *** JOB 19912103 ON sb042 CANCELLED AT 2024-02-01T02:52:58 ***
